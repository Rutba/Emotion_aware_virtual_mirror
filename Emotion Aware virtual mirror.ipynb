{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c48e74",
   "metadata": {},
   "source": [
    "Its a system that uses a webcam to capture a person's facial expression, analyze their emotions, and respond with appropriate visual or textual feedback â€” like a smart mirror that can \"perceive\" how you're feeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1361542",
   "metadata": {},
   "source": [
    "### This project simulates the human perceptual process:\n",
    "    * Visual sensing (camera as the eye)\n",
    "    * Interpretation (emotion recognition via machine learning)\n",
    "    * Emotional response (feedback on screen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd725e8a",
   "metadata": {},
   "source": [
    "### How it can help:\n",
    "    * it can help in mental health monitoring\n",
    "    * Can be used in smart mirrors, educational robots, or autistic care assistants\n",
    "    * Encourages self-awareness in users by reflecting emotional state\n",
    "    * Useful for health, education, caregiving, and wellness tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a6ad2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.8.0.76)\n",
      "Collecting fer\n",
      "  Obtaining dependency information for fer from https://files.pythonhosted.org/packages/19/d7/cc5954aac8db0be7eaff31c5cd059c23af59391d228c9d09cead0250bdae/fer-22.5.1-py3-none-any.whl.metadata\n",
      "  Using cached fer-22.5.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from fer) (3.7.1)\n",
      "Collecting opencv-contrib-python (from fer)\n",
      "  Obtaining dependency information for opencv-contrib-python from https://files.pythonhosted.org/packages/7f/8c/ec631100261b0fca25cafd1e1a06592e50b3cda8aa08e7c4c14d7b4d7115/opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata\n",
      "  Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fer) (2.13.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from fer) (1.5.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from fer) (2.31.0)\n",
      "Collecting facenet-pytorch (from fer)\n",
      "  Obtaining dependency information for facenet-pytorch from https://files.pythonhosted.org/packages/ed/2e/2d56386bc2f834cdc683743903852cf1428b4e5ee119f16cf808b589d3cd/facenet_pytorch-2.6.0-py3-none-any.whl.metadata\n",
      "  Using cached facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fer) (4.65.0)\n",
      "Collecting moviepy (from fer)\n",
      "  Obtaining dependency information for moviepy from https://files.pythonhosted.org/packages/9a/73/7d3b2010baa0b5eb1e4dfa9e4385e89b6716be76f2fa21a6c0fe34b68e5a/moviepy-2.2.1-py3-none-any.whl.metadata\n",
      "  Using cached moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: ffmpeg==1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fer) (1.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from fer) (10.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->fer) (0.4.6)\n",
      "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch->fer)\n",
      "  Obtaining dependency information for torch<2.3.0,>=2.2.0 from https://files.pythonhosted.org/packages/c9/88/d6185582c48159c2be57d56d1d8833f2bee65dd5bf28ada05ac260d0baa2/torch-2.2.2-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached torch-2.2.2-cp38-cp38-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch->fer)\n",
      "  Obtaining dependency information for torchvision<0.18.0,>=0.17.0 from https://files.pythonhosted.org/packages/ed/18/8a11fab0771226e8df4ead963bded04e3603c77b8cae82cd0263f9e19d18/torchvision-0.17.2-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.17.2-cp38-cp38-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fer) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fer) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fer) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->fer) (2023.7.22)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->fer) (5.2.0)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from moviepy->fer) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from moviepy->fer) (2.26.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy->fer)\n",
      "  Obtaining dependency information for imageio_ffmpeg>=0.2.0 from https://files.pythonhosted.org/packages/a9/1c/1b9c72bf839def47626436ea5ebaf643404f7850482c5fafd71a3deeaa94/imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl.metadata\n",
      "  Using cached imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of moviepy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting moviepy (from fer)\n",
      "  Obtaining dependency information for moviepy from https://files.pythonhosted.org/packages/10/0a/bceca4c999fe670fb58ff0e58eb9811e6176d5a62ad5d282e5a581e07ed2/moviepy-2.2.0-py3-none-any.whl.metadata\n",
      "  Using cached moviepy-2.2.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Obtaining dependency information for moviepy from https://files.pythonhosted.org/packages/61/ee/ef46fdfbdc7e1316da60142ffc1867e6e12a22341636dce62856bb325272/moviepy-2.1.2-py3-none-any.whl.metadata\n",
      "  Using cached moviepy-2.1.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Obtaining dependency information for moviepy from https://files.pythonhosted.org/packages/00/7b/edcb99095b403906becbeb61539123e391b22ec418eb0954a34d39a0bc83/moviepy-2.1.1-py3-none-any.whl.metadata\n",
      "  Using cached moviepy-2.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Obtaining dependency information for moviepy from https://files.pythonhosted.org/packages/87/5b/279a5fd9f8bab17f676ec8bf5ed34b4fd342fc6337c96b68ba4fa501f2a8/moviepy-2.1.0-py3-none-any.whl.metadata\n",
      "  Using cached moviepy-2.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Obtaining dependency information for moviepy from https://files.pythonhosted.org/packages/a5/af/b1ac4ed4f88a19dfcad21b210036ae58d274977ac09666f5bd60121817a3/moviepy-2.0.0-py3-none-any.whl.metadata\n",
      "  Using cached moviepy-2.0.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "  Using cached moviepy-1.0.3-py3-none-any.whl\n",
      "Collecting decorator<5.0,>=4.0.2 (from moviepy->fer)\n",
      "  Obtaining dependency information for decorator<5.0,>=4.0.2 from https://files.pythonhosted.org/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl.metadata\n",
      "  Using cached decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting proglog<=1.0.0 (from moviepy->fer)\n",
      "  Obtaining dependency information for proglog<=1.0.0 from https://files.pythonhosted.org/packages/c1/1b/f7ea6cde25621cd9236541c66ff018f4268012a534ec31032bcb187dc5e7/proglog-0.1.12-py3-none-any.whl.metadata\n",
      "  Using cached proglog-0.1.12-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->fer) (2022.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from imageio_ffmpeg>=0.2.0->moviepy->fer) (68.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->fer) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->fer) (1.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch->fer) (1.2.1)\n",
      "Using cached fer-22.5.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
      "Using cached opencv_contrib_python-4.12.0.88-cp37-abi3-win_amd64.whl (45.3 MB)\n",
      "Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Using cached imageio_ffmpeg-0.5.1-py3-none-win_amd64.whl (22.6 MB)\n",
      "Using cached proglog-0.1.12-py3-none-any.whl (6.3 kB)\n",
      "Using cached torch-2.2.2-cp38-cp38-win_amd64.whl (198.6 MB)\n",
      "Using cached torchvision-0.17.2-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: opencv-contrib-python, imageio_ffmpeg, decorator, torch, proglog, torchvision, moviepy, facenet-pytorch, fer\n",
      "Successfully installed decorator-4.4.2 facenet-pytorch-2.6.0 fer-22.5.1 imageio_ffmpeg-0.5.1 moviepy-1.0.3 opencv-contrib-python-4.12.0.88 proglog-0.1.12 torch-2.2.2 torchvision-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for tensorflow-intel: [Errno 13] Permission denied\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\user\\anaconda3\\lib\\site-packages)\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\USER\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.0.2 requires torch==2.0.1, but you have torch 2.2.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --user opencv-python fer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fccc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from fer import FER\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30355920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Emotion-Aware Mirror (Press 'q' to quit)...\n",
      "Emotion logged: neutral\n",
      "Emotion logged: neutral\n",
      "Emotion logged: neutral\n",
      "Emotion logged: sad\n",
      "Emotion logged: angry\n",
      "Emotion logged: sad\n",
      "Emotion logged: neutral\n",
      "Emotion logged: neutral\n",
      "Emotion logged: neutral\n"
     ]
    }
   ],
   "source": [
    "# === Emotion Logger Function ===\n",
    "def log_emotion(emotion):\n",
    "    df = pd.DataFrame([[datetime.now(), emotion]], columns=[\"timestamp\", \"emotion\"])\n",
    "    df.to_csv(\"emotion_log.csv\", mode='a', header=False, index=False)\n",
    "    print(f\"Emotion logged: {emotion}\")\n",
    "\n",
    "\n",
    "# Initialize the webcam and emotion detector\n",
    "cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
    "emotion_detector = FER(mtcnn=True)\n",
    "\n",
    "print(\"Starting Emotion-Aware Mirror (Press 'q' to quit)...\")\n",
    "\n",
    "# === Cooldown setup ===\n",
    "last_logged_time = 0\n",
    "cooldown = 5  # seconds\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Could not read frame from camera\")\n",
    "        break\n",
    "    \n",
    "     # Detect emotion in the frame\n",
    "    emotion_results = emotion_detector.detect_emotions(frame)\n",
    "\n",
    "    for result in emotion_results:\n",
    "        (x, y, w, h) = result[\"box\"]\n",
    "        emotions = result[\"emotions\"]\n",
    "        top_emotion = max(emotions, key=emotions.get)\n",
    "\n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the top emotion\n",
    "        label = f\"{top_emotion}: {emotions[top_emotion]*100:.1f}%\"\n",
    "        cv2.putText(frame, label, (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "        # Smart response (perceptual feedback)\n",
    "        if top_emotion == \"happy\":\n",
    "            response = \"You look great today!\"\n",
    "        elif top_emotion == \"sad\":\n",
    "            response = \"Stay strong. You're doing your best!\"\n",
    "        elif top_emotion == \"angry\":\n",
    "            response = \"Take a deep breath. You've got this.\"\n",
    "        elif top_emotion == \"surprise\":\n",
    "            response = \"Something exciting happening?\"\n",
    "        else:\n",
    "            response = \"Hope you're having a good day.\"\n",
    "\n",
    "        # Show response on screen\n",
    "        cv2.putText(frame, response, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 0, 255), 2)\n",
    "        \n",
    "        # Log the emotion with cooldown\n",
    "        current_time = time.time()\n",
    "        if current_time - last_logged_time > cooldown:\n",
    "            log_emotion(top_emotion)\n",
    "            last_logged_time = current_time\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Emotion-Aware Mirror\", frame)\n",
    "\n",
    "    # Break on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becac90",
   "metadata": {},
   "source": [
    "### Log Emotions and Give Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a28094",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_detected = top_emotion\n",
    "\n",
    "'''\n",
    "# Assume this is the emotion detected\n",
    "emotion_detected = \"angry\"\n",
    "\n",
    "# Save to CSV log\n",
    "def log_emotion(emotion):\n",
    "    df = pd.DataFrame([[datetime.now(), emotion]], columns=[\"timestamp\", \"emotion\"])\n",
    "    df.to_csv(\"emotion_log.csv\", mode='a', header=False, index=False)\n",
    "    print(f\"Emotion logged: {emotion}\")\n",
    "\n",
    "'''\n",
    "# Respond with wellness suggestion\n",
    "def suggest_wellness(emotion):\n",
    "    suggestions = {\n",
    "        \"happy\": \"Keep up the positive energy!\",\n",
    "        \"sad\": \"Try a 5-minute meditation or talk to someone.\",\n",
    "        \"angry\": \"Take a break, deep breaths help.\",\n",
    "        \"surprise\": \"Something unexpected? Stay grounded.\",\n",
    "        \"neutral\": \" You seem calm. Good time for focus.\",\n",
    "        \"fear\": \"You may be anxious. Try calming music.\",\n",
    "        \"disgust\": \"Step away from unpleasant things if possible.\"\n",
    "    }\n",
    "    print(f\"Suggestion: {suggestions.get(emotion, 'Stay strong and be kind to yourself.')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6e1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize emotion trends\n",
    "def plot_emotion_trend():\n",
    "    try:\n",
    "        df = pd.read_csv(\"emotion_log.csv\", names=[\"timestamp\", \"emotion\"], parse_dates=[\"timestamp\"])\n",
    "        df[\"date\"] = df[\"timestamp\"].dt.date\n",
    "        trend = df.groupby([\"date\", \"emotion\"]).size().unstack().fillna(0)\n",
    "\n",
    "        trend.plot(kind=\"bar\", stacked=True, figsize=(10,5))\n",
    "        plt.title(\"Daily Emotion Trends\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Emotion Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"Could not generate chart:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbd05cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion logged: neutral\n",
      "Suggestion: You seem calm. Good time for focus.\n",
      "Could not generate chart: Can only use .dt accessor with datetimelike values\n"
     ]
    }
   ],
   "source": [
    "# Use it\n",
    "log_emotion(emotion_detected)\n",
    "suggest_wellness(emotion_detected)\n",
    "plot_emotion_trend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11472073",
   "metadata": {},
   "source": [
    "### Launch a Meditation or Sound Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "984a5f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "def open_meditation():\n",
    "    # Open a calming YouTube video\n",
    "    webbrowser.open(\"https://www.youtube.com/watch?v=inpok4MKVLM\")  # 5-min meditation\n",
    "\n",
    "if emotion_detected in [\"sad\", \"angry\", \"fear\", \"neutral\"]:\n",
    "    open_meditation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350da12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
